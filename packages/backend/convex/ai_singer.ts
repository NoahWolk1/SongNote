import { action } from "./_generated/server";
import { v } from "convex/values";

// TTS-based AI Singer using free TTS API
class TTSBasedAISinger {
  private sampleRate = 22050;

  async generateSinging(lyrics: string, voiceStyle: string = "pop", mood: string = "happy", pitch: number = 0, includeMusic: boolean = true): Promise<{ audio: string; duration: number; synthesisMethod: string }> {
    console.log(`üéµ Generating singing for: "${lyrics}" (${voiceStyle}, ${mood})`);
    
    try {
      // Step 1: Generate speech using free TTS API
      const speechAudio = await this.generateFreeTTSSpeech(lyrics);
      
      // Step 2: Apply musical pitch modifications
      const singingAudio = await this.applyMusicalPitch(speechAudio, lyrics, voiceStyle, mood, pitch);
      
      // Step 3: Add musical accompaniment if requested
      let finalAudio = singingAudio;
      let synthesisMethod = "free_tts_with_musical_pitch";
      
      if (includeMusic) {
        finalAudio = await this.addMusicalAccompaniment(singingAudio, voiceStyle, mood);
        synthesisMethod = "free_tts_with_musical_pitch_and_accompaniment";
      }
      
      // Step 4: Convert to base64
      const audioBase64 = await this.audioToBase64(finalAudio);
      
      const duration = finalAudio.length / this.sampleRate;
      
      console.log(`‚úÖ Generated ${duration.toFixed(1)}s of singing audio`);
      
      return {
        audio: audioBase64,
        duration,
        synthesisMethod
      };
      
    } catch (error) {
      console.error("‚ùå AI singing generation failed:", error);
      throw new Error(`Failed to generate singing: ${error}`);
    }
  }

  private async generateFreeTTSSpeech(text: string): Promise<Float32Array> {
    console.log("üé§ Generating free TTS speech for:", text);
    
    try {
      // Try using a free TTS service - VoiceRSS has a free tier
      const encodedText = encodeURIComponent(text);
      const url = `https://api.voicerss.org/?key=free&hl=en-us&src=${encodedText}&c=MP3&f=44khz_16bit_stereo&r=0&b64=true`;
      
      const response = await fetch(url);
      
      if (!response.ok) {
        throw new Error(`Free TTS API failed: ${response.status}`);
      }
      
      const audioData = await response.arrayBuffer();
      return this.convertAudioBufferToFloat32Array(audioData);
      
    } catch (error) {
      console.log("Free TTS API failed, using enhanced mathematical synthesis:", error);
      return this.generateEnhancedSpeech(text);
    }
  }

  private async generateEnhancedSpeech(text: string): Promise<Float32Array> {
    console.log("üîÑ Using enhanced mathematical synthesis");
    
    // Enhanced mathematical synthesis that sounds more like speech
    const words = text.toLowerCase().split(' ').filter(word => word.length > 0);
    const totalDuration = words.length * 0.8;
    const samples = Math.floor(totalDuration * this.sampleRate);
    const audio = new Float32Array(samples);
    
    for (let i = 0; i < samples; i++) {
      const time = i / this.sampleRate;
      const wordIndex = Math.floor(time / 0.8);
      const word = words[wordIndex] || words[words.length - 1];
      
      // Generate speech-like sound for this word
      const speechSound = this.generateWordSpeech(word, time);
      
      // Apply word envelope
      const wordStart = wordIndex * 0.8;
      const wordProgress = (time - wordStart) / 0.8;
      
      let envelope = 1.0;
      if (wordProgress < 0.1) {
        envelope = wordProgress / 0.1; // Attack
      } else if (wordProgress > 0.8) {
        envelope = (1.0 - wordProgress) / 0.2; // Release
      }
      
      audio[i] = speechSound * envelope * 0.6;
    }
    
    return audio;
  }

  private generateWordSpeech(word: string, time: number): number {
    // Generate speech-like sound that's more recognizable
    let speechSound = 0;
    
    // Get word characteristics
    const wordData = this.getWordCharacteristics(word);
    
    // Fundamental frequency
    speechSound += Math.sin(2 * Math.PI * wordData.f0 * time) * wordData.amplitude;
    
    // Add harmonics for richness
    speechSound += Math.sin(2 * Math.PI * wordData.f0 * 2 * time) * wordData.amplitude * 0.4;
    speechSound += Math.sin(2 * Math.PI * wordData.f0 * 3 * time) * wordData.amplitude * 0.2;
    
    // Add formants for vowel clarity
    for (const formant of wordData.formants) {
      speechSound += Math.sin(2 * Math.PI * formant * time) * wordData.formantAmplitude;
    }
    
    // Add consonant characteristics
    if (wordData.hasConsonants) {
      const consonantFreq = wordData.f0 * 3.0;
      speechSound += Math.sin(2 * Math.PI * consonantFreq * time) * wordData.consonantAmplitude;
      
      // Add noise for fricatives
      if (wordData.hasFricatives) {
        speechSound += (Math.random() - 0.5) * wordData.noiseAmplitude;
      }
    }
    
    return speechSound;
  }

  private getWordCharacteristics(word: string): any {
    const wordLower = word.toLowerCase();
    
    // Common words with specific characteristics
    if (wordLower === 'hello' || wordLower === 'hi') {
      return {
        f0: 180,
        amplitude: 0.7,
        formants: [800, 1200, 2400],
        formantAmplitude: 0.3,
        hasConsonants: true,
        consonantAmplitude: 0.2,
        hasFricatives: true,
        noiseAmplitude: 0.1
      };
    }
    
    if (wordLower === 'world' || wordLower === 'earth') {
      return {
        f0: 160,
        amplitude: 0.7,
        formants: [600, 1000, 2200],
        formantAmplitude: 0.3,
        hasConsonants: true,
        consonantAmplitude: 0.2,
        hasFricatives: true,
        noiseAmplitude: 0.1
      };
    }
    
    if (wordLower === 'love' || wordLower === 'heart') {
      return {
        f0: 200,
        amplitude: 0.7,
        formants: [700, 1100, 2400],
        formantAmplitude: 0.3,
        hasConsonants: true,
        consonantAmplitude: 0.2,
        hasFricatives: false,
        noiseAmplitude: 0.05
      };
    }
    
    if (wordLower === 'you' || wordLower === 'me') {
      return {
        f0: 170,
        amplitude: 0.7,
        formants: [300, 2200, 3000],
        formantAmplitude: 0.3,
        hasConsonants: true,
        consonantAmplitude: 0.2,
        hasFricatives: false,
        noiseAmplitude: 0.05
      };
    }
    
    // Default characteristics based on word properties
    const vowelCount = (wordLower.match(/[aeiou]/g) || []).length;
    const consonantCount = (wordLower.match(/[bcdfghjklmnpqrstvwxz]/g) || []).length;
    const hasFricatives = /[fvhsz]/.test(wordLower);
    
    return {
      f0: 150 + (vowelCount * 15) + (word.length * 5),
      amplitude: 0.6 + (vowelCount * 0.05),
      formants: [500 + vowelCount * 50, 1500 + vowelCount * 100, 2400],
      formantAmplitude: 0.25 + (vowelCount * 0.02),
      hasConsonants: consonantCount > 0,
      consonantAmplitude: 0.15 + (consonantCount * 0.01),
      hasFricatives: hasFricatives,
      noiseAmplitude: hasFricatives ? 0.08 : 0.05
    };
  }

  private convertAudioBufferToFloat32Array(audioBuffer: ArrayBuffer): Float32Array {
    // Convert audio buffer to Float32Array
    // For now, return a simple conversion - in a real implementation this would handle different audio formats
    return new Float32Array(audioBuffer);
  }

  private async applyMusicalPitch(speechAudio: Float32Array, text: string, voiceStyle: string, mood: string, pitch: number): Promise<Float32Array> {
    console.log("üéõÔ∏è Applying musical pitch to speech");
    
    const processedAudio = new Float32Array(speechAudio.length);
    
    // Get musical scale for pitch variations
    const musicalScale = this.getMusicalScale(voiceStyle, mood);
    let scaleIndex = 0;
    
    // Apply pitch modifications to the speech
    for (let i = 0; i < speechAudio.length; i++) {
      const time = i / this.sampleRate;
      const wordIndex = Math.floor(time / 0.8);
      const wordProgress = (time - (wordIndex * 0.8)) / 0.8;
      
      // Get the original speech sample
      const originalSample = speechAudio[i];
      
      // Calculate pitch shift based on musical scale
      const musicalPitch = musicalScale[scaleIndex % musicalScale.length];
      const totalPitchShift = musicalPitch + pitch;
      const pitchMultiplier = Math.pow(2, totalPitchShift / 12);
      
      // Apply pitch shifting (preserve speech clarity)
      const shiftedSample = this.pitchShiftSample(originalSample, pitchMultiplier, time);
      
      // Mix original speech with pitch-shifted version
      processedAudio[i] = originalSample * 0.9 + shiftedSample * 0.1;
      
      // Add vibrato for singing effect
      const vibratoFreq = 5.5; // 5.5 Hz vibrato
      const vibratoDepth = 0.005;
      const vibrato = Math.sin(2 * Math.PI * vibratoFreq * time) * vibratoDepth;
      processedAudio[i] *= (1 + vibrato);
      
      // Move to next musical note every few words
      if (wordProgress > 0.9) {
        scaleIndex++;
      }
    }
    
    return processedAudio;
  }

  private pitchShiftSample(sample: number, pitchMultiplier: number, time: number): number {
    // Simple pitch shifting by frequency multiplication
    return sample * pitchMultiplier;
  }

  private getMusicalScale(voiceStyle: string, mood: string): number[] {
    // Musical scales for different styles and moods
    const scales = {
      pop: [0, 2, 4, 5, 7, 9, 11, 12], // C major scale
      ballad: [0, 2, 3, 5, 7, 8, 10, 12], // C minor scale
      jazz: [0, 2, 4, 6, 7, 9, 11, 12], // C lydian scale
    };
    
    let scale = scales[voiceStyle as keyof typeof scales] || scales.pop;
    
    // Adjust scale based on mood
    if (mood === 'sad') {
      scale = scale.map(note => note - 2); // Lower pitch
    } else if (mood === 'energetic') {
      scale = scale.map(note => note + 2); // Higher pitch
    }
    
    return scale;
  }

  private async addMusicalAccompaniment(vocalAudio: Float32Array, voiceStyle: string, mood: string): Promise<Float32Array> {
    console.log("üéπ Adding musical accompaniment");
    
    const duration = vocalAudio.length / this.sampleRate;
    const accompaniment = new Float32Array(vocalAudio.length);
    
    // Generate chord progression
    const chords = this.generateChordProgression(voiceStyle, mood);
    const chordDuration = duration / chords.length;
    
    for (let i = 0; i < vocalAudio.length; i++) {
      const time = i / this.sampleRate;
      const chordIndex = Math.floor(time / chordDuration);
      const chord = chords[chordIndex] || chords[chords.length - 1];
      
      // Generate chord tones
      let chordSum = 0;
      for (const note of chord) {
        chordSum += Math.sin(2 * Math.PI * note * time) * 0.03;
      }
      
      accompaniment[i] = chordSum;
    }
    
    // Mix vocals and accompaniment (vocals are the star!)
    const mixedAudio = new Float32Array(vocalAudio.length);
    for (let i = 0; i < vocalAudio.length; i++) {
      mixedAudio[i] = vocalAudio[i] * 0.95 + accompaniment[i] * 0.05; // 95% vocals, 5% music
    }
    
    return mixedAudio;
  }

  private generateChordProgression(voiceStyle: string, mood: string): number[][] {
    // Simple chord progressions
    const progressions = {
      pop: [[261.63, 329.63, 392.00], [293.66, 349.23, 440.00], [329.63, 415.30, 493.88], [261.63, 329.63, 392.00]], // C major, D major, E major, C major
      ballad: [[261.63, 329.63, 392.00], [293.66, 349.23, 440.00], [329.63, 415.30, 493.88], [293.66, 349.23, 440.00]], // C major, D major, E major, D major
      jazz: [[261.63, 329.63, 392.00, 493.88], [293.66, 349.23, 440.00, 523.25], [329.63, 415.30, 493.88, 587.33], [261.63, 329.63, 392.00, 493.88]] // 7th chords
    };
    
    return progressions[voiceStyle as keyof typeof progressions] || progressions.pop;
  }

  private async audioToBase64(audio: Float32Array): Promise<string> {
    // Convert Float32Array to WAV format and then to base64
    const wavBuffer = this.float32ArrayToWav(audio);
    const base64 = this.arrayBufferToBase64(wavBuffer);
    return base64;
  }

  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    // Convert ArrayBuffer to base64 without using Buffer
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }

  private float32ArrayToWav(audio: Float32Array): ArrayBuffer {
    const sampleRate = this.sampleRate;
    const numChannels = 1;
    const bitsPerSample = 16;
    const byteRate = sampleRate * numChannels * bitsPerSample / 8;
    const blockAlign = numChannels * bitsPerSample / 8;
    const dataSize = audio.length * 2; // 16-bit samples
    const fileSize = 36 + dataSize;
    
    const buffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(buffer);
    
    // WAV header
    view.setUint32(0, 0x52494646, false); // "RIFF"
    view.setUint32(4, fileSize, true);
    view.setUint32(8, 0x57415645, false); // "WAVE"
    view.setUint32(12, 0x666D7420, false); // "fmt "
    view.setUint32(16, 16, true); // fmt chunk size
    view.setUint16(20, 1, true); // PCM format
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, byteRate, true);
    view.setUint16(32, blockAlign, true);
    view.setUint16(34, bitsPerSample, true);
    view.setUint32(36, 0x64617461, false); // "data"
    view.setUint32(40, dataSize, true);
    
    // Audio data
    let offset = 44;
    for (let i = 0; i < audio.length; i++) {
      const sample = Math.max(-1, Math.min(1, audio[i]));
      const intSample = Math.round(sample * 32767);
      view.setInt16(offset, intSample, true);
      offset += 2;
    }
    
    return buffer;
  }
}

// Create a singleton instance
const aiSinger = new TTSBasedAISinger();

export const generateSinging = action({
  args: {
    lyrics: v.string(),
    voiceStyle: v.optional(v.string()),
    mood: v.optional(v.string()),
    includeMusic: v.optional(v.boolean()),
    ttsEngine: v.optional(v.string()),
    pitchAdjustment: v.optional(v.number()),
  },
  handler: async (ctx, args) => {
    console.log("üé§ Generating singing with free TTS-based AI Singer");
    
    try {
      const result = await aiSinger.generateSinging(
        args.lyrics,
        args.voiceStyle || "pop",
        args.mood || "happy",
        args.pitchAdjustment || 0,
        args.includeMusic ?? true
      );
      
      return {
        success: true,
        audio: result.audio,
        duration_seconds: result.duration,
        synthesis_method: result.synthesisMethod,
        message: "Singing generated successfully"
      };
      
    } catch (error) {
      console.error("‚ùå Singing generation failed:", error);
      return {
        success: false,
        error: error instanceof Error ? error.message : "Unknown error",
        message: "Failed to generate singing"
      };
    }
  },
}); 